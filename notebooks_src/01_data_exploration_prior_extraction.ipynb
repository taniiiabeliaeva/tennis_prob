{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504cd78c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.11.6)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/tanbe/tennis_prob/venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from scipy.stats import beta as beta_dist\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent \n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "PROCESSED_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01b29c7",
   "metadata": {},
   "source": [
    "**In this ipynb we establish robust Bayesian priors for player performance using historical 2023 Wimbledon data**\n",
    "\n",
    "Objectives: \n",
    "- Data Cleaning: Reconstruct missing FirstServeIn statistics using point-level ServeNumber logic.\n",
    "\n",
    "- Prior Elicitation: Extract player-specific beliefs (Serve %, Ace Rate) from 2023 matches.\n",
    "\n",
    "- Variance Inflation: Weaken historical priors to allow the 2024 target match data to drive the posterior updates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b30645",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be95ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_2023 = pd.read_csv(DATA_DIR / '2023-wimbledon-matches.csv')\n",
    "points_2023 = pd.read_csv(DATA_DIR / '2023-wimbledon-points.csv')\n",
    "\n",
    "matches_2024 = pd.read_csv(DATA_DIR / '2024-wimbledon-matches.csv')\n",
    "points_2024 = pd.read_csv(DATA_DIR / '2024-wimbledon-points.csv')\n",
    "\n",
    "print(f\"2023 Matches: {len(matches_2023)} rows\")\n",
    "print(f\"2023 Points: {len(points_2023)} rows\")\n",
    "print(f\"2024 Matches: {len(matches_2024)} rows\")\n",
    "print(f\"2024 Points: {len(points_2024)} rows\")\n",
    "\n",
    "# Check critical columns in points data\n",
    "critical_cols = ['match_id', 'PointNumber', 'PointServer', 'PointWinner', \n",
    "                 'ServeNumber', 'P1FirstSrvIn', 'P2FirstSrvIn', 'P1Ace', 'P2Ace']\n",
    "\n",
    "print(\"\\nMissing values in critical columns (2024):\")\n",
    "missing_2024 = points_2024[critical_cols].isnull().sum()\n",
    "print(missing_2024[missing_2024 > 0])\n",
    "\n",
    "print(\"\\nMissing values in critical columns (2023):\")\n",
    "missing_2023 = points_2023[critical_cols].isnull().sum()\n",
    "print(missing_2023[missing_2023 > 0])\n",
    "\n",
    "# Assess ServeNumber column\n",
    "print(\"\\n ServeNumber distribution (2024):\")\n",
    "print(points_2024['ServeNumber'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5b06f4",
   "metadata": {},
   "source": [
    "## Data Cleaning: Reconstructing Serve Statistics\n",
    "The raw point-by-point data contains missing values for FirstServeIn. We reconstruct this using the ServeNumber column which is fully populated.\n",
    "\n",
    "**Logic:**\n",
    "\n",
    "- ServeNumber = 1: The point ended on the first serve. Therefore, the first serve was IN. (Attempts +1, Made +1).\n",
    "\n",
    "- ServeNumber = 2: The point required a second serve. Therefore, the first serve was OUT. (Attempts +1, Made +0).\n",
    "\n",
    "This reconstruction creates the \"Silver\" layer of our data, which will be saved for all downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd98275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- helper functions ---\n",
    "\n",
    "def calculate_first_serve_stats(points_df):\n",
    "    \"\"\"\n",
    "    Calculate cumulative first serve statistics from ServeNumber column.\n",
    "    \n",
    "    CORRECTED LOGIC (per-point):\n",
    "    - ServeNumber=1: First serve IN (increment attempts AND in)\n",
    "    - ServeNumber=2: First serve OUT (increment attempts only)\n",
    "    - ServeNumber=0: Metadata (skip)\n",
    "    \n",
    "    Args:\n",
    "        points_df: DataFrame with match-point data\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with P1FirstSrvIn, P1FirstSrvTotal, P2FirstSrvIn, P2FirstSrvTotal\n",
    "    \"\"\"\n",
    "    df = points_df.copy()\n",
    "    \n",
    "    # initialize counters\n",
    "    df['P1FirstSrvIn'] = 0\n",
    "    df['P2FirstSrvIn'] = 0\n",
    "    df['P1FirstSrvTotal'] = 0\n",
    "    df['P2FirstSrvTotal'] = 0\n",
    "    \n",
    "    # iterate by match to ensure counters reset\n",
    "    # using a vectorized approach where possible would be faster, but row iteration is safer for cumulative running states\n",
    "    for match_id in df['match_id'].unique():\n",
    "        mask = df['match_id'] == match_id\n",
    "        match_points = df[mask].copy()\n",
    "        \n",
    "        p1_in, p1_total = 0, 0\n",
    "        p2_in, p2_total = 0, 0\n",
    "        \n",
    "        # storage for this match\n",
    "        p1_in_vals, p1_tot_vals = [], []\n",
    "        p2_in_vals, p2_tot_vals = [], []\n",
    "        \n",
    "        for _, row in match_points.iterrows():\n",
    "            server = row['PointServer']\n",
    "            serve_num = row['ServeNumber']\n",
    "            \n",
    "            if serve_num == 1:\n",
    "                # first serve went in\n",
    "                if server == 1:\n",
    "                    p1_total += 1\n",
    "                    p1_in += 1\n",
    "                elif server == 2:\n",
    "                    p2_total += 1\n",
    "                    p2_in += 1\n",
    "            elif serve_num == 2:\n",
    "                # second serve implies first serve missed\n",
    "                if server == 1:\n",
    "                    p1_total += 1\n",
    "                elif server == 2:\n",
    "                    p2_total += 1\n",
    "            \n",
    "            p1_in_vals.append(p1_in)\n",
    "            p1_tot_vals.append(p1_total)\n",
    "            p2_in_vals.append(p2_in)\n",
    "            p2_tot_vals.append(p2_total)\n",
    "            \n",
    "        # assign back\n",
    "        df.loc[mask, 'P1FirstSrvIn'] = p1_in_vals\n",
    "        df.loc[mask, 'P1FirstSrvTotal'] = p1_tot_vals\n",
    "        df.loc[mask, 'P2FirstSrvIn'] = p2_in_vals\n",
    "        df.loc[mask, 'P2FirstSrvTotal'] = p2_tot_vals\n",
    "        \n",
    "    return df\n",
    "\n",
    "def get_beta_params(successes, total, inflation_factor=10):\n",
    "    \"\"\"\n",
    "    Compute beta parameters (alpha, beta) using method of moments.\n",
    "    applies variance inflation (dividing n by factor) to weaken the prior.\n",
    "    \"\"\"\n",
    "    if total == 0:\n",
    "        return {'alpha': 1, 'beta': 1, 'mean': 0.5}\n",
    "        \n",
    "    # inflate variance to allow new data to speak\n",
    "    adj_success = successes / inflation_factor\n",
    "    adj_total = total / inflation_factor\n",
    "    adj_fail = adj_total - adj_success\n",
    "    \n",
    "    # add minimal smoothing\n",
    "    alpha = adj_success + 1\n",
    "    beta = adj_fail + 1\n",
    "    \n",
    "    return {\n",
    "        'alpha': alpha,\n",
    "        'beta': beta,\n",
    "        'mean': alpha / (alpha + beta)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c05393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstructing missing serve statistics\n",
    "points_2023_corr = calculate_first_serve_stats(points_2023)\n",
    "points_2024_corr = calculate_first_serve_stats(points_2024)\n",
    "\n",
    "# Visualization: Match Length Distribution\n",
    "match_lengths = points_2024_corr.groupby('match_id').size()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(match_lengths, bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.axvline(326, color='red', linestyle='--', label='Target Match (Sinner/Medvedev) = 326')\n",
    "plt.title('Distribution of Match Lengths (2024 Wimbledon)')\n",
    "plt.xlabel('Points per Match')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# save files\n",
    "points_2023_corr.to_csv(PROCESSED_DIR / '2023-wimbledon-points-corrected.csv', index=False)\n",
    "points_2024_corr.to_csv(PROCESSED_DIR / '2024-wimbledon-points-corrected.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaeb54a",
   "metadata": {},
   "source": [
    "## Statistical Methodology: Beta Priors\n",
    "\n",
    "We model serve probabilities using the Beta distribution, which is the conjugate prior for the Binomial likelihood.\n",
    "\n",
    "**Key Formula**\n",
    "\n",
    "For a Beta($\\alpha, \\beta$) distribution:\n",
    "\n",
    "- Mean: $\\mu = \\frac{\\alpha}{\\alpha + \\beta}\n",
    "\n",
    "- Variance: $\\sigma^2 = \\frac{\\alpha\\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}$\n",
    "\n",
    "**Variance Inflation Strategy**\n",
    "\n",
    "We apply a variance inflation factor of 10 to the historical 2023 counts.\n",
    "\n",
    "- Why? Tennis players evolve. A hard prior based on hundreds of 2023 points would overwhelm the signal from the specific 2024 match we are analyzing.\n",
    "\n",
    "- Method: We divide the observed counts ($n$) by 10 before adding the smoothing constants. This widens the distribution (increases uncertainty) while keeping the mean centered on the historical average.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02bc0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beta_params(successes, total, inflation_factor=10):\n",
    "    \"\"\"\n",
    "    Compute Beta parameters (alpha, beta) using variance inflation.\n",
    "    \n",
    "    Args:\n",
    "        successes (int): Number of successful events (e.g., Serve In)\n",
    "        total (int): Total number of attempts\n",
    "        inflation_factor (int): Divisor for counts to increase prior variance\n",
    "    \"\"\"\n",
    "    if total == 0:\n",
    "        return {'alpha': 1, 'beta': 1, 'mean': 0.5}\n",
    "        \n",
    "    # Apply variance inflation\n",
    "    adj_success = successes / inflation_factor\n",
    "    adj_total = total / inflation_factor\n",
    "    adj_fail = adj_total - adj_success\n",
    "    \n",
    "    # Add Laplace smoothing (+1) to prevent zero-mass tails\n",
    "    alpha = adj_success + 1\n",
    "    beta = adj_fail + 1\n",
    "    \n",
    "    return {\n",
    "        'alpha': alpha,\n",
    "        'beta': beta,\n",
    "        'mean': alpha / (alpha + beta)\n",
    "    }\n",
    "\n",
    "# Define Players\n",
    "target_p1 = \"Jannik Sinner\"\n",
    "target_p2 = \"Daniil Medvedev\"\n",
    "\n",
    "# Filter Match IDs\n",
    "p1_matches = matches_2023[\n",
    "    (matches_2023['player1'] == target_p1) | \n",
    "    (matches_2023['player2'] == target_p1)\n",
    "]['match_id'].unique()\n",
    "\n",
    "p2_matches = matches_2023[\n",
    "    (matches_2023['player1'] == target_p2) | \n",
    "    (matches_2023['player2'] == target_p2)\n",
    "]['match_id'].unique()\n",
    "\n",
    "priors = {}\n",
    "\n",
    "# Extraction Loop\n",
    "for player, match_ids in [(target_p1, p1_matches), (target_p2, p2_matches)]:\n",
    "    total_srv_in = 0\n",
    "    total_srv_att = 0\n",
    "    total_aces = 0\n",
    "    total_srv_points = 0\n",
    "    \n",
    "    for mid in match_ids:\n",
    "        m_pts = points_2023_corr[points_2023_corr['match_id'] == mid]\n",
    "        m_meta = matches_2023[matches_2023['match_id'] == mid].iloc[0]\n",
    "        \n",
    "        if m_pts.empty: continue\n",
    "            \n",
    "        if m_meta['player1'] == player:\n",
    "            last_pt = m_pts.iloc[-1]\n",
    "            total_srv_in += last_pt['P1FirstSrvIn']\n",
    "            total_srv_att += last_pt['P1FirstSrvTotal']\n",
    "            total_aces += m_pts[m_pts['PointServer'] == 1]['P1Ace'].sum()\n",
    "            total_srv_points += len(m_pts[m_pts['PointServer'] == 1])\n",
    "            \n",
    "        elif m_meta['player2'] == player:\n",
    "            last_pt = m_pts.iloc[-1]\n",
    "            total_srv_in += last_pt['P2FirstSrvIn']\n",
    "            total_srv_att += last_pt['P2FirstSrvTotal']\n",
    "            total_aces += m_pts[m_pts['PointServer'] == 2]['P2Ace'].sum()\n",
    "            total_srv_points += len(m_pts[m_pts['PointServer'] == 2])\n",
    "\n",
    "    clean_name = player.lower().replace(\" \", \"_\")\n",
    "    \n",
    "    # Compute Parameters\n",
    "    priors[clean_name] = {\n",
    "        'serve_pct': get_beta_params(total_srv_in, total_srv_att),\n",
    "        'ace_rate': get_beta_params(total_aces, total_srv_points),\n",
    "        'stats': {\n",
    "            'matches': len(match_ids),\n",
    "            'points_served': total_srv_points,\n",
    "            'obs_serve_pct': total_srv_in / total_srv_att if total_srv_att else 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Output Validation Stats\n",
    "    print(f\"\\n {player} (2023) \")\n",
    "    print(f\"Matches: {len(match_ids)} | Points Served: {total_srv_points}\")\n",
    "    print(f\"Observed Serve %: {priors[clean_name]['stats']['obs_serve_pct']:.3f}\")\n",
    "    print(f\"Prior Mean (Inflated): {priors[clean_name]['serve_pct']['mean']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff83fd7",
   "metadata": {},
   "source": [
    "## Prior  Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34a534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 1000)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot First Serve %\n",
    "ax = axes[0]\n",
    "for player in [target_p1, target_p2]:\n",
    "    key = player.lower().replace(\" \", \"_\")\n",
    "    params = priors[key]['serve_pct']\n",
    "    y = beta_dist.pdf(x, params['alpha'], params['beta'])\n",
    "    ax.plot(x, y, label=f\"{player} (μ={params['mean']:.2f})\", linewidth=2)\n",
    "\n",
    "ax.set_title('Prior Distributions: First Serve %')\n",
    "ax.set_xlabel('Probability')\n",
    "ax.set_ylabel('Density')\n",
    "ax.legend()\n",
    "\n",
    "# Plot Ace Rate\n",
    "ax = axes[1]\n",
    "for player in [target_p1, target_p2]:\n",
    "    key = player.lower().replace(\" \", \"_\")\n",
    "    params = priors[key]['ace_rate']\n",
    "    y = beta_dist.pdf(x, params['alpha'], params['beta'])\n",
    "    ax.plot(x, y, label=f\"{player} (μ={params['mean']:.2f})\", linewidth=2)\n",
    "\n",
    "ax.set_title('Prior Distributions: Ace Rate')\n",
    "ax.set_xlabel('Probability')\n",
    "ax.set_ylabel('Density')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save Priors for downstream modeling\n",
    "output_path = PROCESSED_DIR / 'priors_2023.pkl'\n",
    "with open(output_path, 'wb') as f:\n",
    "    pickle.dump(priors, f)\n",
    "\n",
    "print(f\"Priors dictionary saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fab9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed Statistical Validation\n",
    "print(\"Prior Validation (comparing to observed 2023 data):\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "for player in [target_p1, target_p2]:\n",
    "    key = player.lower().replace(\" \", \"_\")\n",
    "    stats = priors[key]['stats']\n",
    "    prior_srv = priors[key]['serve_pct']\n",
    "    prior_ace = priors[key]['ace_rate']\n",
    "    \n",
    "    print(f\"\\n{player}:\")\n",
    "    \n",
    "    print(f\"  First Serve %:\")\n",
    "    print(f\"    Observed (2023): {stats['obs_serve_pct']:.3f}\")\n",
    "    print(f\"    Prior Mean:      {prior_srv['mean']:.3f}\")\n",
    "    print(f\"    Difference:      {abs(stats['obs_serve_pct'] - prior_srv['mean']):.3f}\")\n",
    "\n",
    "    print(f\"\\n  Ace Rate:\")\n",
    "    print(f\"    Observed (2023): {stats['obs_ace_rate']:.3f}\")\n",
    "    print(f\"    Prior Mean:      {prior_ace['mean']:.3f}\")\n",
    "    print(f\"    Difference:      {abs(stats['obs_ace_rate'] - prior_ace['mean']):.3f}\")\n",
    "\n",
    "#Note: Priors should be CLOSE to observed values (within ~0.01-0.02)\n",
    "#Large differences indicate potential data quality issues."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
